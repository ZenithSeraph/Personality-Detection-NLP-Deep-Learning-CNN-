{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Hyperparameters\n",
    "These will be required for building the neural network. We can play around with these and they will largely affect the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_len =1000\n",
    "batch_size = 32\n",
    "embedding_dims =10\n",
    "filters = 16\n",
    "ker_size = 3 # kernel size\n",
    "hidden_dims = 250\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mbti_cleaned.csv')\n",
    "data.dropna(inplace=True)  # ignoring the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>50</td>\n",
       "      <td>intj moments    sportscenter    plays    pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>50</td>\n",
       "      <td>finding  lack    these posts very alarmingsex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>50</td>\n",
       "      <td>good       course  which    know thats  blessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>youre firedthats another silly misconception t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>109</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>that even anatomically possibleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>111</td>\n",
       "      <td>INFP</td>\n",
       "      <td>50</td>\n",
       "      <td>have this toothough theyre usually almost   p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>112</td>\n",
       "      <td>INFP</td>\n",
       "      <td>50</td>\n",
       "      <td>feel like everyone  this thread just needs  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>113</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>50</td>\n",
       "      <td>splinter cell blacklist  xbox   generally well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>114</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>50</td>\n",
       "      <td>nobody   same  realistically   impossible  bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  type  Number of posts  \\\n",
       "0            0  INFJ               50   \n",
       "1            1  ENTP               50   \n",
       "2            2  INTP               50   \n",
       "3            3  INTJ               50   \n",
       "4            4  ENTJ               50   \n",
       "..         ...   ...              ...   \n",
       "95         109  INTJ               50   \n",
       "96         111  INFP               50   \n",
       "97         112  INFP               50   \n",
       "98         113  ESTP               50   \n",
       "99         114  ISTP               50   \n",
       "\n",
       "                                                Posts  \n",
       "0     intj moments    sportscenter    plays    pra...  \n",
       "1    finding  lack    these posts very alarmingsex...  \n",
       "2   good       course  which    know thats  blessi...  \n",
       "3   dear intp    enjoyed  conversation  other   es...  \n",
       "4   youre firedthats another silly misconception t...  \n",
       "..                                                ...  \n",
       "95                   that even anatomically possibleu  \n",
       "96   have this toothough theyre usually almost   p...  \n",
       "97   feel like everyone  this thread just needs  c...  \n",
       "98  splinter cell blacklist  xbox   generally well...  \n",
       "99  nobody   same  realistically   impossible  bas...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th>Posts</th>\n",
       "      <th>E_I</th>\n",
       "      <th>N_S</th>\n",
       "      <th>F_T</th>\n",
       "      <th>J_P</th>\n",
       "      <th>E_I_code</th>\n",
       "      <th>N_S_code</th>\n",
       "      <th>F_T_code</th>\n",
       "      <th>J_P_code</th>\n",
       "      <th>type_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>intj moments    sportscenter    plays    pra...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01.01.01.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>finding  lack    these posts very alarmingsex...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01.00.00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>INTP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>good       course  which    know thats  blessi...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01.00.00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01.00.01.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>youre firedthats another silly misconception t...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01.00.01.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type  Number of posts  \\\n",
       "0         0.0  INFJ             50.0   \n",
       "1         1.0  ENTP             50.0   \n",
       "2         2.0  INTP             50.0   \n",
       "3         3.0  INTJ             50.0   \n",
       "4         4.0  ENTJ             50.0   \n",
       "\n",
       "                                               Posts E_I N_S F_T J_P  \\\n",
       "0    intj moments    sportscenter    plays    pra...   I   N   F   J   \n",
       "1   finding  lack    these posts very alarmingsex...   E   N   T   P   \n",
       "2  good       course  which    know thats  blessi...   I   N   T   P   \n",
       "3  dear intp    enjoyed  conversation  other   es...   I   N   T   J   \n",
       "4  youre firedthats another silly misconception t...   E   N   T   J   \n",
       "\n",
       "   E_I_code  N_S_code  F_T_code  J_P_code     type_code  \n",
       "0       0.0       1.0       1.0       1.0  0.01.01.01.0  \n",
       "1       1.0       1.0       0.0       0.0  1.01.00.00.0  \n",
       "2       0.0       1.0       0.0       0.0  0.01.00.00.0  \n",
       "3       0.0       1.0       0.0       1.0  0.01.00.01.0  \n",
       "4       1.0       1.0       0.0       1.0  1.01.00.01.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add empty columns for trait pairs\n",
    "data = data.reindex(columns = data.columns.tolist() + ['E_I','N_S','F_T','J_P'])\n",
    "# split MBTI into trait pair column values\n",
    "for i in range(data.shape[0]):\n",
    "    data.loc[i,'E_I'] = data.iloc[i,1][0]\n",
    "    data.loc[i,'N_S'] = data.iloc[i,1][1]\n",
    "    data.loc[i,'F_T'] = data.iloc[i,1][2]\n",
    "    data.loc[i,'J_P'] = data.iloc[i,1][3]\n",
    "# create dictionary of trait pair binary encoding values\n",
    "mbti_binary_values = {'E': 1, 'I': 0, 'N': 1, 'S': 0, 'F': 1, 'T': 0, 'J': 1, 'P': 0}\n",
    "# create columns of trait pairs as binary encoded values\n",
    "for col in data.columns[-4:]:\n",
    "    data[f'{col}_code'] = data[col].map(mbti_binary_values)\n",
    "# create column of type as binary code\n",
    "data['type_code'] = data.iloc[:,-4:].apply(lambda x: ''.join(x.values.astype(str)), axis=1)  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_I_code</th>\n",
       "      <th>N_S_code</th>\n",
       "      <th>F_T_code</th>\n",
       "      <th>J_P_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7587 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      E_I_code  N_S_code  F_T_code  J_P_code\n",
       "0          0.0       1.0       1.0       1.0\n",
       "1          1.0       1.0       0.0       0.0\n",
       "2          0.0       1.0       0.0       0.0\n",
       "3          0.0       1.0       0.0       1.0\n",
       "4          1.0       1.0       0.0       1.0\n",
       "...        ...       ...       ...       ...\n",
       "7057       0.0       1.0       0.0       0.0\n",
       "7181       0.0       1.0       1.0       1.0\n",
       "7212       0.0       0.0       0.0       0.0\n",
       "7237       0.0       1.0       1.0       0.0\n",
       "7465       0.0       0.0       1.0       0.0\n",
       "\n",
       "[7587 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot encoding on the dataset output classes \n",
    "y = pd.DataFrame(data[['E_I_code','N_S_code','F_T_code', 'J_P_code']])\n",
    "x_train,x_test,y_train,y_test = train_test_split(data['Posts'], y,random_state=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733    good good   though  have never been sure about...\n",
       "5063    well  have  strong belief note  said belief th...\n",
       "6044    this though  console myself that  usually only...\n",
       "1139    thank   forgot  reply  this  talk   casually w...\n",
       "298     would someone  isnt happy have  avatar like th...\n",
       "                              ...                        \n",
       "3908    very smilish   intj     fellow enfps  some rea...\n",
       "4504     seems sara from tegan  sara   infpive been th...\n",
       "351        react  them   even begin  comprehend them w...\n",
       "2618      please have  account retired  time thanksgee...\n",
       "3629    what   mean  thought myers bridds   percentage...\n",
       "Name: Posts, Length: 1897, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.fillna('')\n",
    "x_test = x_test.fillna('')\n",
    "tokenizer = text.Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973      some thoughts  erik better known   phantom  ...\n",
       "2593    youre both still individuals sure  might belon...\n",
       "6954    this   status that  posted  facebook  other  t...\n",
       "623        actually thought   going  score   more towa...\n",
       "5291    welcome   forum hope   enjoy  here welcome   f...\n",
       "                              ...                        \n",
       "4957    sorry  this     quite frankly bullshit   victi...\n",
       "3280        enfp   nutshell shes worked  whole life  s...\n",
       "1663       quiet area   librarynot pretty  allfor   id...\n",
       "2621    obama   wolf  sheeps clothing  think  malaise ...\n",
       "2746    skateboarding music whatever instrument taekwo...\n",
       "Name: Posts, Length: 5690, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_matrix(x_train)\n",
    "x_test = tokenizer.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train,maxlen=max_len)\n",
    "x_test = pad_sequences(x_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequential Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First we add an embedding layer \n",
    "model.add(Embedding(vocab_size,embedding_dims,input_length=max_len)) \n",
    "# Adding a 1D convolutional Layer\n",
    "model.add(Conv1D(filters, ker_size, padding='valid', activation='relu'))\n",
    "# Max Pooling the Convolutions\n",
    "model.add(MaxPooling1D())\n",
    "# Again Computing the Convolutions\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "178/178 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2d0cd7490>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the modeL\n",
    "model.fit(x_train,y_train, batch_size=batch_size, epochs=15, validation_data=(x_test, y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.2699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.9899845123291"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)[1]*100  # Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model into a pickle file \n",
    "import pickle\n",
    "pickle.dump(model,open('cnn_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer,open('tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Single Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s ='Idealistic, loyal to their values and to people who are important to them. Want an external life that is congruent with their values. Curious, quick to see possibilities, can be catalysts for implementing ideas. Seek to understand people and to help them fulfill their potential. Adaptable, flexible, and accepting unless a value is threatened.'\n",
    "s = pd.Series(s)\n",
    "s= tokenizer.texts_to_matrix(s)\n",
    "s = sequence.pad_sequences(s)\n",
    "l = model.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= l[0][0]*(1/1999), l[0][1]*(1/1197)\n",
    "a = a/(1/1999)+(1/1197)\n",
    "b = b/(1/1999)+(1/1197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [a,b,l[0][2],l[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Personality is: INTP\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "if l[0] >0.5:\n",
    "    s +='E'\n",
    "else:\n",
    "    s+='I'\n",
    "if l[1] >0.5:\n",
    "    s+='S'\n",
    "else:\n",
    "    s+='N'\n",
    "if l[2] >0.5:\n",
    "    s+='T'\n",
    "else:\n",
    "    s+='F'\n",
    "if l[3] >0.5:\n",
    "    s+='J'\n",
    "else:\n",
    "    s+='P'\n",
    "print('Your Personality is:',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
