{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 11:00:04.689565: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Hyperparameters\n",
    "These will be required for building the neural network. We can play around with these and they will largely affect the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_len =1000\n",
    "batch_size = 32\n",
    "embedding_dims =10\n",
    "filters = 16\n",
    "ker_size = 3 # kernel size\n",
    "hidden_dims = 250\n",
    "epochs_i = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mbti_cleaned.csv')\n",
    "data.dropna(inplace=True)  # ignoring the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th>Posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>50</td>\n",
       "      <td>intj moments    sportscenter    plays    pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>50</td>\n",
       "      <td>finding  lack    these posts very alarmingsex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>50</td>\n",
       "      <td>good       course  which    know thats  blessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>youre firedthats another silly misconception t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>109</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50</td>\n",
       "      <td>that even anatomically possibleu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>111</td>\n",
       "      <td>INFP</td>\n",
       "      <td>50</td>\n",
       "      <td>have this toothough theyre usually almost   p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>112</td>\n",
       "      <td>INFP</td>\n",
       "      <td>50</td>\n",
       "      <td>feel like everyone  this thread just needs  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>113</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>50</td>\n",
       "      <td>splinter cell blacklist  xbox   generally well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>114</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>50</td>\n",
       "      <td>nobody   same  realistically   impossible  bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  type  Number of posts  \\\n",
       "0            0  INFJ               50   \n",
       "1            1  ENTP               50   \n",
       "2            2  INTP               50   \n",
       "3            3  INTJ               50   \n",
       "4            4  ENTJ               50   \n",
       "..         ...   ...              ...   \n",
       "95         109  INTJ               50   \n",
       "96         111  INFP               50   \n",
       "97         112  INFP               50   \n",
       "98         113  ESTP               50   \n",
       "99         114  ISTP               50   \n",
       "\n",
       "                                                Posts  \n",
       "0     intj moments    sportscenter    plays    pra...  \n",
       "1    finding  lack    these posts very alarmingsex...  \n",
       "2   good       course  which    know thats  blessi...  \n",
       "3   dear intp    enjoyed  conversation  other   es...  \n",
       "4   youre firedthats another silly misconception t...  \n",
       "..                                                ...  \n",
       "95                   that even anatomically possibleu  \n",
       "96   have this toothough theyre usually almost   p...  \n",
       "97   feel like everyone  this thread just needs  c...  \n",
       "98  splinter cell blacklist  xbox   generally well...  \n",
       "99  nobody   same  realistically   impossible  bas...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>Number of posts</th>\n",
       "      <th>Posts</th>\n",
       "      <th>E_I</th>\n",
       "      <th>N_S</th>\n",
       "      <th>F_T</th>\n",
       "      <th>J_P</th>\n",
       "      <th>E_I_code</th>\n",
       "      <th>N_S_code</th>\n",
       "      <th>F_T_code</th>\n",
       "      <th>J_P_code</th>\n",
       "      <th>type_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>intj moments    sportscenter    plays    pra...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01.01.01.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>finding  lack    these posts very alarmingsex...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01.00.00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>INTP</td>\n",
       "      <td>50.0</td>\n",
       "      <td>good       course  which    know thats  blessi...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01.00.00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>dear intp    enjoyed  conversation  other   es...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01.00.01.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>50.0</td>\n",
       "      <td>youre firedthats another silly misconception t...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01.00.01.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type  Number of posts  \\\n",
       "0         0.0  INFJ             50.0   \n",
       "1         1.0  ENTP             50.0   \n",
       "2         2.0  INTP             50.0   \n",
       "3         3.0  INTJ             50.0   \n",
       "4         4.0  ENTJ             50.0   \n",
       "\n",
       "                                               Posts E_I N_S F_T J_P  \\\n",
       "0    intj moments    sportscenter    plays    pra...   I   N   F   J   \n",
       "1   finding  lack    these posts very alarmingsex...   E   N   T   P   \n",
       "2  good       course  which    know thats  blessi...   I   N   T   P   \n",
       "3  dear intp    enjoyed  conversation  other   es...   I   N   T   J   \n",
       "4  youre firedthats another silly misconception t...   E   N   T   J   \n",
       "\n",
       "   E_I_code  N_S_code  F_T_code  J_P_code     type_code  \n",
       "0       0.0       1.0       1.0       1.0  0.01.01.01.0  \n",
       "1       1.0       1.0       0.0       0.0  1.01.00.00.0  \n",
       "2       0.0       1.0       0.0       0.0  0.01.00.00.0  \n",
       "3       0.0       1.0       0.0       1.0  0.01.00.01.0  \n",
       "4       1.0       1.0       0.0       1.0  1.01.00.01.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add empty columns for trait pairs\n",
    "data = data.reindex(columns = data.columns.tolist() + ['E_I','N_S','F_T','J_P'])\n",
    "# split MBTI into trait pair column values\n",
    "for i in range(data.shape[0]):\n",
    "    data.loc[i,'E_I'] = data.iloc[i,1][0]\n",
    "    data.loc[i,'N_S'] = data.iloc[i,1][1]\n",
    "    data.loc[i,'F_T'] = data.iloc[i,1][2]\n",
    "    data.loc[i,'J_P'] = data.iloc[i,1][3]\n",
    "# create dictionary of trait pair binary encoding values\n",
    "mbti_binary_values = {'E': 1, 'I': 0, 'N': 1, 'S': 0, 'F': 1, 'T': 0, 'J': 1, 'P': 0}\n",
    "# create columns of trait pairs as binary encoded values\n",
    "for col in data.columns[-4:]:\n",
    "    data[f'{col}_code'] = data[col].map(mbti_binary_values)\n",
    "# create column of type as binary code\n",
    "data['type_code'] = data.iloc[:,-4:].apply(lambda x: ''.join(x.values.astype(str)), axis=1)  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encoding on the dataset output classes \n",
    "y = pd.DataFrame(data[['E_I_code','N_S_code','F_T_code', 'J_P_code']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data['Posts'], y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.fillna('')\n",
    "x_test = x_test.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_matrix(x_train)\n",
    "x_test = tokenizer.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train,maxlen=max_len)\n",
    "x_test = pad_sequences(x_test,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequential Neural Network using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First we add an embedding layer \n",
    "model.add(Embedding(vocab_size,embedding_dims,input_length=max_len)) \n",
    "# Adding a 1D convolutional Layer\n",
    "model.add(Conv1D(filters, ker_size, padding='valid', activation='relu'))\n",
    "# Max Pooling the Convolutions\n",
    "model.add(MaxPooling1D())\n",
    "# Again Computing the Convolutions\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation='relu'))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "178/178 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.2699 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 2/5\n",
      "178/178 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 3/5\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 4/5\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n",
      "Epoch 5/5\n",
      "178/178 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.2698 - val_loss: nan - val_accuracy: 0.2699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85d23688b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the modeL\n",
    "model.fit(x_train,y_train, batch_size=batch_size, epochs=5, validation_data=(x_test, y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.2699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.9899845123291"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)[1]*100  # Accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model into a pickle file \n",
    "import pickle\n",
    "pickle.dump(model,open('cnn_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer,open('tokenizer','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Single Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "s ='live or not live thats a problem'\n",
    "s = pd.Series(s)\n",
    "s= tokenizer.texts_to_matrix(s)\n",
    "s = pad_sequences(s)\n",
    "l = model.predict(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= l[0][0]*(1/1999), l[0][1]*(1/1197)\n",
    "a = a/(1/1999)+(1/1197)\n",
    "b = b/(1/1999)+(1/1197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [a,b,l[0][2],l[0][3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Personality is: INFP\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "if l[0] >0.5:\n",
    "    s +='E'\n",
    "else:\n",
    "    s+='I'\n",
    "if l[1] >0.5:\n",
    "    s+='S'\n",
    "else:\n",
    "    s+='N'\n",
    "if l[2] >0.5:\n",
    "    s+='T'\n",
    "else:\n",
    "    s+='F'\n",
    "if l[3] >0.5:\n",
    "    s+='J'\n",
    "else:\n",
    "    s+='P'\n",
    "print('Your Personality is:',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
